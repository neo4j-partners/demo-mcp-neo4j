# Complete Guide: Deploying MCP Neo4j Server to Databricks Apps

**Last Updated**: 2025-11-01
**Status**: Production Ready ‚úÖ
**Deployment Time**: ~10 minutes

---

## Table of Contents

1. [Overview](#overview)
2. [The Problem & Solution](#the-problem--solution)
3. [Critical Changes Required](#critical-changes-required)
4. [Secret Management](#secret-management)
5. [Lazy Driver Initialization](#lazy-driver-initialization)
6. [Step-by-Step Deployment](#step-by-step-deployment)
7. [Testing & Validation](#testing--validation)
8. [Troubleshooting](#troubleshooting)
9. [Architecture & Design Decisions](#architecture--design-decisions)

---

## Overview

This guide documents the complete process of deploying the MCP Neo4j Cypher server to Databricks Apps, including all the issues encountered and how they were resolved.

### What This Server Does

The MCP Neo4j Cypher server provides three tools for interacting with a Neo4j graph database:

1. **get_neo4j_schema** - Returns the complete graph schema (nodes, properties, relationships)
2. **read_neo4j_cypher** - Execute read-only Cypher queries
3. **write_neo4j_cypher** - Execute write Cypher queries (if not in read-only mode)

### Current Deployment

- **App Name**: mcp-neo4j-cypher
- **Status**: RUNNING ‚úÖ
- **URL**: https://mcp-neo4j-cypher-1098933906466604.4.azure.databricksapps.com
- **Transport**: HTTP (modern MCP transport)
- **Endpoint**: `/mcp`

---

## The Problem & Solution

### Challenge 1: Async Driver Initialization ‚ö†Ô∏è

**The Problem**:

The original MCP Neo4j server code created the Neo4j async driver at module initialization time:

```python
# ‚ùå BROKEN - This crashes in Databricks Apps
from neo4j import AsyncGraphDatabase

# Driver created at module level, BEFORE event loop exists
neo4j_driver = AsyncGraphDatabase.driver(uri, auth=(username, password))

def create_mcp_server(neo4j_driver, ...):
    # Server tries to use driver...
    pass

# Later when server starts
mcp.run(transport="http", ...)  # ‚Üê This starts the event loop
```

**Why This Breaks**:

1. `AsyncGraphDatabase.driver()` creates async resources
2. These resources need an event loop to exist
3. But the event loop isn't created until `mcp.run()` is called
4. In Databricks Apps environment, this causes immediate crashes
5. No error logs, just silent exit with CRASHED state

**The Solution - Lazy Initialization**:

Defer driver creation until it's actually needed (inside an async context):

```python
# ‚úÖ WORKS - Lazy initialization
def create_mcp_server(
    neo4j_uri: str,
    neo4j_username: str,
    neo4j_password: str,
    ...
):
    _driver: Optional[AsyncDriver] = None

    def get_driver() -> AsyncDriver:
        """Lazily create driver on first use"""
        nonlocal _driver
        if _driver is None:
            # Read from environment (survives FastMCP context)
            uri = os.getenv("NEO4J_URI")
            username = os.getenv("NEO4J_USERNAME")
            password = os.getenv("NEO4J_PASSWORD")

            # Create driver NOW (inside async context)
            _driver = AsyncGraphDatabase.driver(uri, auth=(username, password))
        return _driver

    @mcp.tool
    async def get_neo4j_schema(...):
        # Driver is created here, when tool is first called
        results = await get_driver().execute_query(...)
```

**Key Changes**:

1. **No driver parameter**: `create_mcp_server()` no longer accepts a driver instance
2. **Environment variables**: Reads credentials from environment instead of parameters
3. **Lazy creation**: Driver is created inside `get_driver()` on first tool call
4. **Async context**: Driver creation happens AFTER event loop is running

**Why Environment Variables**:

The initial approach tried to pass credentials as parameters to `create_mcp_server()`, but those values were lost in the FastMCP closure. Reading directly from `os.getenv()` inside `get_driver()` ensures credentials are always accessible.

---

### Challenge 2: Secret Management üîê

**The Problem**:

Databricks Apps does NOT support the `{{secrets/scope/key}}` syntax that works in notebooks and clusters.

```yaml
# ‚ùå DOESN'T WORK in Databricks Apps (only works in notebooks)
env:
  - name: NEO4J_PASSWORD
    value: "{{secrets/mcp-neo4j-cypher/neo4j-password}}"
```

This results in the environment variable containing the **literal string** `"{{secrets/mcp-neo4j-cypher/neo4j-password}}"` instead of the actual password!

**Evidence**:

```python
# What we saw when debugging
password = os.getenv("NEO4J_PASSWORD")
print(len(password))  # 46 characters
print(password[:10])  # "{{secrets/..."

# Expected (actual password)
print(len(password))  # Should be ~40 characters for actual password
```

**The Solution - valueFrom with UI Resources**:

Databricks Apps requires a three-step process:

**Step 0: Create Databricks Secrets via CLI** (one-time setup)

```bash
# Create the secret scope
databricks secrets create-scope mcp-neo4j-cypher

# Store the actual secret values
databricks secrets put-secret mcp-neo4j-cypher username --string-value "neo4j"
databricks secrets put-secret mcp-neo4j-cypher password --string-value "your-password"
```

**Step 1: Configure App Resources in Databricks UI**

**IMPORTANT**: This links the Databricks secrets to your app. This MUST be done through the UI.

1. Navigate to: **Compute** ‚Üí **Apps** ‚Üí **mcp-neo4j-cypher**
2. Click: **"Edit app"** (top right)
3. Go to step: **"2 Configure"**
4. Scroll to: **"App resources"** section
5. Click: **"+ Add resource"**
6. Configure each secret resource:
   - **Resource type**: Secret
   - **Secret scope**: `mcp-neo4j-cypher` (the scope created via CLI)
   - **Secret key**: `username` or `password` (the key in the Databricks secret scope)
   - **Resource key**: `NEO4J_USERNAME` or `NEO4J_PASSWORD` (what you'll reference in app.yaml)
   - **Permission**: Can read
7. Repeat for each secret (username, password, etc.)

**Step 2: Reference Resources in app.yaml with valueFrom**

```yaml
env:
  # ‚úÖ WORKS - References UI-configured resource
  - name: NEO4J_USERNAME
    valueFrom: NEO4J_USERNAME  # Must match the "Resource key" from UI

  - name: NEO4J_PASSWORD
    valueFrom: NEO4J_PASSWORD  # Must match the "Resource key" from UI
```

**Hardcode Non-Sensitive Values**:

```yaml
env:
  # These are NOT sensitive (no credentials exposed)
  - name: NEO4J_URI
    value: "neo4j+s://3f1f827a.databases.neo4j.io"

  - name: NEO4J_DATABASE
    value: "neo4j"
```

**Why This Works**:

- The `valueFrom` field tells Databricks to inject the actual secret value at runtime
- The resource must be configured in the UI first (can't be done via app.yaml alone)
- Non-sensitive config (URI, database name) can be hardcoded for simplicity
- This is the official Microsoft-documented approach for Databricks Apps

**How the Pieces Connect**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Databricks CLI (stores actual secrets)                          ‚îÇ
‚îÇ    databricks secrets put-secret mcp-neo4j-cypher password          ‚îÇ
‚îÇ                                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                   Scope Name    Secret Key          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Databricks UI > Edit App > App Resources                        ‚îÇ
‚îÇ    [+ Add resource]                                                 ‚îÇ
‚îÇ    ‚Ä¢ Secret scope: mcp-neo4j-cypher     ‚Üê Links to CLI scope       ‚îÇ
‚îÇ    ‚Ä¢ Secret key: password                ‚Üê Links to CLI secret key ‚îÇ
‚îÇ    ‚Ä¢ Resource key: NEO4J_PASSWORD        ‚Üê Your custom identifier  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. app.yaml (references the resource)                              ‚îÇ
‚îÇ    env:                                                             ‚îÇ
‚îÇ      - name: NEO4J_PASSWORD                                         ‚îÇ
‚îÇ        valueFrom: NEO4J_PASSWORD  ‚Üê Must match "Resource key"      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Python Code (reads from environment)                            ‚îÇ
‚îÇ    password = os.getenv("NEO4J_PASSWORD")  ‚Üê Gets actual value     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key Relationships**:
- **CLI Secret Scope** ‚Üí **UI Secret Scope**: Must match exactly
- **CLI Secret Key** ‚Üí **UI Secret Key**: Must match exactly
- **UI Resource Key** ‚Üí **app.yaml valueFrom**: Must match exactly
- **app.yaml env name** ‚Üí **Python os.getenv()**: Must match exactly

---

## Critical Changes Required

### Changes to `server.py`

**File**: `src/mcp_neo4j_cypher/server.py`

#### Change 1: Function Signature

```python
# Before
def create_mcp_server(
    neo4j_driver: Optional[AsyncDriver] = None,  # ‚ùå Removed
    ...
) -> FastMCP:

# After
def create_mcp_server(
    neo4j_uri: Optional[str] = None,      # ‚úÖ Not used (reads from env)
    neo4j_username: Optional[str] = None,  # ‚úÖ Not used (reads from env)
    neo4j_password: Optional[str] = None,  # ‚úÖ Not used (reads from env)
    database: str = "neo4j",
    namespace: str = "",
    read_timeout: int = 30,
    token_limit: Optional[int] = None,
    read_only: bool = False,
    config_sample_size: int = 1000,
) -> FastMCP:
```

**Note**: The credential parameters are kept for API compatibility but not used. The function reads directly from environment variables.

#### Change 2: Lazy Driver Initialization

```python
def create_mcp_server(...) -> FastMCP:
    # Module-level driver storage
    _driver: Optional[AsyncDriver] = None

    def get_driver() -> AsyncDriver:
        """
        Get or create the Neo4j driver lazily.

        CRITICAL: Driver must be created inside async context (after event loop starts).
        This is called from async tool functions, not at module initialization.
        """
        nonlocal _driver
        if _driver is None:
            import os

            # Read Neo4j credentials from environment variables
            # These are set by Databricks Apps via valueFrom resources
            uri = os.getenv("NEO4J_URI")
            username = os.getenv("NEO4J_USERNAME")
            password = os.getenv("NEO4J_PASSWORD")

            if not uri or not username or not password:
                missing = []
                if not uri: missing.append("NEO4J_URI")
                if not username: missing.append("NEO4J_USERNAME")
                if not password: missing.append("NEO4J_PASSWORD")
                raise ValueError(
                    f"Missing Neo4j credentials in environment: {', '.join(missing)}. "
                    "These should be provided via Databricks secrets."
                )

            logger.info(f"Creating Neo4j driver lazily to {uri}")
            _driver = AsyncGraphDatabase.driver(uri, auth=(username, password))

        return _driver
```

#### Change 3: Update All Tool Functions

```python
@mcp.tool
async def get_neo4j_schema(sample_size: int = config_sample_size) -> str:
    """Get Neo4j schema"""
    # OLD: neo4j_driver.execute_query(...)
    # NEW: get_driver().execute_query(...)
    results = await get_driver().execute_query(
        query=query,
        database_=database,
        routing_=RoutingControl.READ,
    )
    # ... rest of function

@mcp.tool
async def neo4j_read_query(query: str, params: dict = {}) -> str:
    """Execute read query"""
    results = await get_driver().execute_query(  # ‚Üê Changed
        query=query,
        parameters_=params,
        database_=database,
        routing_=RoutingControl.READ,
    )
    # ... rest of function

@mcp.tool
async def neo4j_write_query(query: str, params: dict = {}) -> str:
    """Execute write query"""
    results = await get_driver().execute_query(  # ‚Üê Changed
        query=query,
        parameters_=params,
        database_=database,
        routing_=RoutingControl.WRITE,
    )
    # ... rest of function
```

**Summary of Changes**:
- Every `neo4j_driver.execute_query()` ‚Üí `get_driver().execute_query()`
- This ensures driver is created lazily on first tool call
- All tools work in async context where event loop exists

---

### Changes to `app.yaml`

**File**: `app.yaml`

```yaml
# Databricks App Configuration for MCP Neo4j Cypher Server

command:
  - "sh"
  - "-c"
  - "pip install -q -r requirements.txt && python production_server.py"

env:
  # ============================================================================
  # Neo4j Connection Configuration
  # ============================================================================

  # Non-sensitive values (hardcoded - no credentials exposed)
  - name: NEO4J_URI
    value: "neo4j+s://3f1f827a.databases.neo4j.io"

  - name: NEO4J_DATABASE
    value: "neo4j"

  # Sensitive values (via Databricks App Resources configured in UI)
  # These reference resources added via: Databricks UI ‚Üí Apps ‚Üí mcp-neo4j-cypher ‚Üí Add resource
  - name: NEO4J_USERNAME
    valueFrom: NEO4J_USERNAME

  - name: NEO4J_PASSWORD
    valueFrom: NEO4J_PASSWORD

  # ============================================================================
  # MCP Server Configuration
  # ============================================================================

  - name: DATABRICKS_APP_PORT
    value: "8000"

  - name: PORT
    value: "8000"

  - name: NEO4J_TRANSPORT
    value: "http"

  - name: NEO4J_MCP_SERVER_HOST
    value: "0.0.0.0"

  - name: NEO4J_MCP_SERVER_PORT
    value: "8000"

  - name: NEO4J_MCP_SERVER_PATH
    value: "/mcp/"

  - name: NEO4J_MCP_SERVER_ALLOWED_HOSTS
    value: "*"

  - name: NEO4J_MCP_SERVER_ALLOW_ORIGINS
    value: "*"
```

**Key Points**:

1. **NEO4J_URI and NEO4J_DATABASE**: Hardcoded (not sensitive)
2. **NEO4J_USERNAME and NEO4J_PASSWORD**: Use `valueFrom` (configured in UI)
3. **Port configuration**: Both DATABRICKS_APP_PORT and PORT set to 8000
4. **Transport**: HTTP (modern MCP protocol)
5. **Security**: CORS and allowed hosts set to "*" for Databricks workspace access

---

### Changes to `production_server.py`

**File**: `production_server.py`

```python
#!/usr/bin/env python3
"""
Production MCP Neo4j Cypher Server for Databricks Apps

This wrapper reads configuration from environment variables set by Databricks Apps
and starts the MCP server with proper lazy driver initialization.
"""

import os
import sys
from src.mcp_neo4j_cypher.server import create_mcp_server

def main():
    """Main entry point for production server"""

    # Read configuration from environment
    # NOTE: Credentials are read by get_driver() in server.py, not here
    neo4j_database = os.getenv("NEO4J_DATABASE", "neo4j")
    port = int(os.getenv("PORT") or os.getenv("DATABRICKS_APP_PORT") or "8000")

    # Optional configuration
    namespace = os.getenv("NEO4J_NAMESPACE", "")
    read_timeout = int(os.getenv("NEO4J_READ_TIMEOUT", "30"))
    token_limit_str = os.getenv("NEO4J_RESPONSE_TOKEN_LIMIT")
    token_limit = int(token_limit_str) if token_limit_str else None
    read_only = os.getenv("NEO4J_READ_ONLY", "false").lower() == "true"
    schema_sample_size = int(os.getenv("NEO4J_SCHEMA_SAMPLE_SIZE", "1000"))

    print("=" * 70)
    print("MCP Neo4j Cypher Server - Production Mode")
    print("=" * 70)
    print(f"Port: {port}")
    print(f"Database: {neo4j_database}")
    print(f"Read-only: {read_only}")
    print(f"Schema sample size: {schema_sample_size}")
    print("=" * 70)

    # Create MCP server with lazy driver initialization
    # Driver will be created on first tool call, not here
    mcp = create_mcp_server(
        database=neo4j_database,
        namespace=namespace,
        read_timeout=read_timeout,
        token_limit=token_limit,
        read_only=read_only,
        config_sample_size=schema_sample_size
    )

    # Start the server
    # This creates the event loop - driver will be created later
    mcp.run(transport="http", host="0.0.0.0", port=port)

if __name__ == "__main__":
    main()
```

**Key Points**:

1. **No driver creation**: The driver is NOT created here
2. **Environment variables**: All config read from environment
3. **Lazy initialization**: Driver will be created when first tool is called
4. **Port handling**: Reads from PORT or DATABRICKS_APP_PORT
5. **HTTP transport**: Uses modern MCP protocol

---

## Secret Management

### Complete Secret Setup Process

#### 1. Create Secret Scope

```bash
# Create the secret scope (one-time setup)
databricks secrets create-scope mcp-neo4j-cypher
```

#### 2. Store Secrets

```bash
# Store Neo4j credentials in Databricks secrets
databricks secrets put-secret mcp-neo4j-cypher username \
  --string-value "neo4j"

databricks secrets put-secret mcp-neo4j-cypher password \
  --string-value "your-actual-password-here"
```

Or use the automated `deploy.sh` script which reads from `neo4j_auth.txt`:

```bash
./deploy.sh
```

#### 3. Configure Resources in Databricks UI

**CRITICAL**: This step MUST be done via the UI. It cannot be automated via app.yaml.

**Workflow Overview**:
1. First, create secrets using Databricks CLI (see step 2 above)
2. Then, add App Resources in the UI to link those secrets to your app
3. The "Resource key" you define in the UI is what you'll reference in `app.yaml` using `valueFrom`

**Detailed Steps**:

1. Open Databricks workspace
2. Navigate to: **Compute** ‚Üí **Apps** ‚Üí **mcp-neo4j-cypher**
3. Click **"Edit app"** (top right)
4. Go to step **"2 Configure"**
5. Scroll to **"App resources"** section
6. Click **"+ Add resource"**

**For Password Resource**:
- **Resource type**: Secret
- **Secret scope**: `mcp-neo4j-cypher` (the scope you created via CLI)
- **Secret key**: `password` (the key in the Databricks secret scope - from CLI step)
- **Resource key**: `NEO4J_PASSWORD` (what you'll reference in app.yaml with valueFrom)
- **Permission**: Can read (or Can manage)
- Click **Add** or **Save**

**For Username Resource**:
- **Resource type**: Secret
- **Secret scope**: `mcp-neo4j-cypher`
- **Secret key**: `username` (the key in the Databricks secret scope - from CLI step)
- **Resource key**: `NEO4J_USERNAME` (what you'll reference in app.yaml with valueFrom)
- **Permission**: Can read (or Can manage)
- Click **Add** or **Save**

**Understanding the Fields**:
- **Secret scope**: The Databricks secret scope created with `databricks secrets create-scope`
- **Secret key**: The key used when storing the secret with `databricks secrets put-secret`
- **Resource key**: The identifier you use in `app.yaml` with `valueFrom: RESOURCE_KEY`
- **Permission**: Access level for the app's service principal to read the secret

**After Adding Resources**:
You should see both resources listed in the "App resources" section showing:
- Secret: neo4j-... (scope prefix)
- Permission: Can read/manage
- Resource key: NEO4J_PASSWORD and NEO4J_USERNAME

#### 4. Update app.yaml to Use valueFrom

```yaml
env:
  - name: NEO4J_USERNAME
    valueFrom: NEO4J_USERNAME  # Must match resource key from UI

  - name: NEO4J_PASSWORD
    valueFrom: NEO4J_PASSWORD  # Must match resource key from UI
```

#### 5. Verify Secret Resolution

After deployment, test that secrets are resolving correctly:

```bash
# Deploy
./deploy.sh

# Test
uv run test_neo4j_tools.py
```

Expected: Neo4j connection successful, schema retrieval works.

**NOT Expected**: Error messages about empty URI or authentication failures.

---

## Lazy Driver Initialization

### The Technical Problem Explained

**Event Loop Lifecycle**:

```
1. Python imports module
2. Module-level code executes
   ‚îú‚îÄ Imports
   ‚îú‚îÄ Variable assignments
   ‚îî‚îÄ Function definitions
3. main() calls mcp.run()
4. mcp.run() creates event loop  ‚Üê Event loop starts HERE
5. Server handles requests
   ‚îî‚îÄ Tool functions execute (in async context)
```

**What Was Breaking**:

```python
# At step 2 (module level):
neo4j_driver = AsyncGraphDatabase.driver(...)  # ‚ùå NO EVENT LOOP YET!

# At step 4:
mcp.run()  # ‚Üê Creates event loop, but driver already broken

# At step 5:
@mcp.tool
async def get_schema():
    neo4j_driver.execute_query(...)  # ‚ùå Crashes - broken driver
```

**Why It Breaks in Databricks Apps**:

- Databricks Apps environment is more restrictive
- Async resources created outside event loop don't work
- In local development, Python is more forgiving
- In Databricks, it causes immediate silent crashes

### The Solution: Lazy Pattern

```python
def create_mcp_server(...):
    # Step 2: Module level - NO driver created
    _driver: Optional[AsyncDriver] = None

    def get_driver() -> AsyncDriver:
        nonlocal _driver
        # Step 5: First tool call - CREATE driver NOW
        if _driver is None:
            # Event loop exists, safe to create driver
            _driver = AsyncGraphDatabase.driver(...)
        return _driver

    @mcp.tool
    async def get_schema():
        # Uses get_driver() - creates on first call
        results = await get_driver().execute_query(...)
```

**Lifecycle with Lazy Loading**:

```
1. Module import - NO driver
2. Module code executes - NO driver
3. mcp.run() called - NO driver
4. Event loop created ‚úÖ
5. First tool called
   ‚îú‚îÄ get_driver() called
   ‚îú‚îÄ Event loop exists ‚úÖ
   ‚îú‚îÄ Driver created NOW ‚úÖ
   ‚îî‚îÄ Query executes ‚úÖ
6. Subsequent tool calls
   ‚îî‚îÄ Driver already exists, reused ‚úÖ
```

### Benefits of This Approach

1. **Works in Databricks Apps**: Driver created in proper async context
2. **Connection Pooling**: Single driver instance reused across all requests
3. **Error Handling**: Clear errors if credentials missing
4. **Performance**: Driver created once, not per-request
5. **Clean Separation**: Configuration vs. initialization

---

## Step-by-Step Deployment

### Prerequisites

1. **Databricks CLI** installed and authenticated:
   ```bash
   databricks auth login
   ```

2. **Neo4j Database** credentials in `neo4j_auth.txt`:
   ```
   NEO4J_URI=neo4j+s://your-host.databases.neo4j.io
   NEO4J_USERNAME=neo4j
   NEO4J_PASSWORD=your-password
   NEO4J_DATABASE=neo4j
   ```

3. **Resources Configured** in Databricks UI (see Secret Management section)

### Deployment Steps

#### Step 1: Verify Configuration

```bash
# Check app.yaml is updated
cat app.yaml | grep -A 5 "NEO4J_USERNAME"

# Should see:
# - name: NEO4J_USERNAME
#   valueFrom: NEO4J_USERNAME
```

#### Step 2: Deploy

```bash
# Run deployment script
./deploy.sh
```

**Expected Output**:
```
==========================================
  Deploying MCP Neo4j Cypher Server
==========================================

üîê Setting up Databricks secrets...
  ‚úÖ Secrets stored successfully

üì§ Syncing files to Databricks workspace...
  ‚úÖ Files synced successfully

üöÄ Deploying app to Databricks...
  ‚úÖ Deployment Complete!
```

#### Step 3: Verify Deployment

```bash
# Check app status
databricks apps get mcp-neo4j-cypher

# Should show:
# "app_status": {
#   "state": "RUNNING"
# }
```

#### Step 4: Test Functionality

```bash
# Run comprehensive tests
uv run test_neo4j_tools.py
```

**Expected Output**:
```
================================================================================
MCP NEO4J CYPHER SERVER - TOOL TESTER
================================================================================

‚úÖ Found 3 tools:
   - get_neo4j_schema
   - read_neo4j_cypher
   - write_neo4j_cypher

================================================================================
TEST 1: Get Neo4j Schema
================================================================================

‚úÖ Schema Response:
{Aircraft, System, Component, ...}

================================================================================
‚úÖ ALL TESTS COMPLETED SUCCESSFULLY!
================================================================================
```

---

## Testing & Validation

### Test Script

**File**: `test_neo4j_tools.py`

This script tests the deployed server by:
1. Connecting via OAuth authentication
2. Listing all available tools
3. Calling get_neo4j_schema
4. Executing sample queries
5. Validating responses

**Usage**:
```bash
# Basic test
uv run test_neo4j_tools.py

# The script is self-contained and uses dependencies from pyproject.toml
```

### Manual Testing

**Test 1: Check App Status**
```bash
databricks apps get mcp-neo4j-cypher | jq '.app_status'
```

**Test 2: View Logs**
```bash
databricks apps logs mcp-neo4j-cypher
```

**Test 3: Test HTTP Endpoint**
```bash
# Get OAuth token
TOKEN=$(databricks auth token)

# Test endpoint (should return 404 for GET, expects POST)
curl -i -H "Authorization: Bearer $TOKEN" \
  https://mcp-neo4j-cypher-1098933906466604.4.azure.databricksapps.com/mcp
```

### Integration Testing

Use the MCP server in a Python notebook or application:

```python
from databricks.sdk import WorkspaceClient
from databricks_mcp import DatabricksOAuthClientProvider
from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client as connect

# Initialize
ws = WorkspaceClient()
MCP_URL = "https://mcp-neo4j-cypher-1098933906466604.4.azure.databricksapps.com/mcp"

# Connect and use
async with connect(MCP_URL, auth=DatabricksOAuthClientProvider(ws)) as (r, w, _):
    async with ClientSession(r, w) as session:
        await session.initialize()

        # Get schema
        schema = await session.call_tool("get_neo4j_schema", {})
        print(schema)

        # Run query
        result = await session.call_tool("read_neo4j_cypher", {
            "query": "MATCH (a:Aircraft) RETURN a.tail_number LIMIT 10"
        })
        print(result)
```

---

## Troubleshooting

### App Status: CRASHED

**Symptoms**:
- App shows state: CRASHED or IDLE
- No error logs
- App exits immediately after starting

**Common Causes**:

1. **Driver created too early (async issue)**
   - Check: Is `AsyncGraphDatabase.driver()` called at module level?
   - Fix: Use lazy initialization pattern (see Lazy Driver section)

2. **Missing dependencies**
   - Check: Is `pip install -r requirements.txt` in app.yaml command?
   - Fix: Ensure command includes: `pip install -q -r requirements.txt && python production_server.py`

3. **Import errors**
   - Check logs: `databricks apps logs mcp-neo4j-cypher`
   - Fix: Ensure all imports are correct and packages listed in requirements.txt

### Secrets Not Resolving

**Symptoms**:
- Environment variables contain literal strings like `"{{secrets/...}}"`
- Neo4j connection fails with authentication errors
- Error: "URI scheme '' is not supported"

**Diagnosis**:
```bash
# Check what the app sees
# Add temporary debug tool to server:
@mcp.tool
def debug_env() -> dict:
    return {
        "uri": os.getenv("NEO4J_URI"),
        "username_len": len(os.getenv("NEO4J_USERNAME", "")),
        "password_len": len(os.getenv("NEO4J_PASSWORD", "")),
    }
```

**Fixes**:

1. **Using {{secrets/...}} syntax**
   - Problem: This doesn't work in Databricks Apps
   - Fix: Switch to valueFrom approach (see Secret Management section)

2. **Resources not configured in UI**
   - Problem: valueFrom references non-existent resources
   - Fix: Add resources in Databricks UI (Apps ‚Üí mcp-neo4j-cypher ‚Üí Add resource)

3. **Mismatched resource keys**
   - Problem: app.yaml references "NEO4J_PASSWORD" but UI has "PASSWORD"
   - Fix: Ensure resource key in UI matches valueFrom in app.yaml

### Connection Timeouts

**Symptoms**:
- Tools time out after 30 seconds
- Error: "Query timeout"

**Fixes**:

1. **Increase timeout**:
   ```yaml
   env:
     - name: NEO4J_READ_TIMEOUT
       value: "60"
   ```

2. **Optimize queries**:
   - Use LIMIT clauses
   - Add indexes to Neo4j
   - Reduce sample_size for schema queries

3. **Check Neo4j connection**:
   ```bash
   # Test from local machine
   cypher-shell -a neo4j+s://your-host.databases.neo4j.io \
     -u neo4j -p your-password
   ```

### Tool Discovery Fails

**Symptoms**:
- Client can connect but no tools found
- Error: "No tools available"

**Fixes**:

1. **Check endpoint URL**:
   - Must include `/mcp` path
   - Correct: `https://app-url.com/mcp`
   - Wrong: `https://app-url.com`

2. **Check transport**:
   - Server must use: `mcp.run(transport="http", ...)`
   - Client must use: `streamablehttp_client`

3. **Check OAuth authentication**:
   ```bash
   databricks auth login
   ```

---

## Architecture & Design Decisions

### Why Lazy Initialization?

**Alternatives Considered**:

1. **Eager initialization** (original approach)
   - ‚ùå Crashes in Databricks Apps
   - ‚ùå Event loop doesn't exist yet

2. **Per-request driver creation**
   - ‚ùå Poor performance (connection overhead)
   - ‚ùå Connection pool thrashing

3. **FastMCP lifecycle hooks**
   - ‚ùå Not available in FastMCP API
   - ‚ùå Would need custom implementation

4. **Lazy initialization** (chosen approach)
   - ‚úÖ Works in Databricks Apps
   - ‚úÖ Single driver instance (good performance)
   - ‚úÖ Clean separation of concerns
   - ‚úÖ Clear error messages

### Why valueFrom Instead of {{secrets/...}}?

**Technical Reasons**:

1. **Platform Limitation**: Azure Databricks Apps doesn't support secret interpolation via `{{secrets/...}}` syntax
2. **Official Approach**: Microsoft documentation specifies valueFrom for Apps
3. **Security**: Resources are managed by platform, not exposed in app.yaml
4. **Flexibility**: Can reference secrets from different scopes

**Tradeoffs**:

- **Pro**: More secure, official approach, works reliably
- **Con**: Requires UI configuration (can't fully automate)
- **Pro**: Clear separation between config and secrets
- **Con**: Extra step in deployment process

### Why Hardcode URI and Database?

**Rationale**:

1. **Not Sensitive**: Neo4j URI doesn't contain credentials
2. **Simplicity**: Fewer secrets to manage
3. **Reference Pattern**: Proven working approach from reference implementation
4. **Flexibility**: Easy to change in app.yaml without touching secrets

**When NOT to Hardcode**:

- Multi-environment deployments (dev/staging/prod with different URIs)
- Frequent URI changes
- Shared app.yaml across different Neo4j instances

In those cases, make URI a resource too:
```yaml
- name: NEO4J_URI
  valueFrom: NEO4J_URI  # Configure in UI like other secrets
```

### Why HTTP Transport?

**HTTP vs SSE**:

| Aspect | HTTP (Streamable) | SSE |
|--------|------------------|-----|
| Status | Current standard | Legacy |
| Performance | Better | Adequate |
| Compatibility | Modern clients | Older clients |
| Future | Actively developed | May deprecate |

**Decision**: Use HTTP transport (`transport="http"`) as it's the modern standard and better supported.

---

## Summary of What Was Broken vs Fixed

### What Was Broken

1. **Async Driver Creation Timing**
   - Driver created at module level before event loop existed
   - Caused immediate crashes in Databricks Apps
   - No error messages, just silent exits

2. **Secret Syntax**
   - Used `{{secrets/scope/key}}` syntax from notebooks
   - Secrets showed as literal strings instead of values
   - Neo4j connection failed with empty credentials

3. **Parameter Passing**
   - Tried passing credentials as function parameters
   - Values lost in FastMCP closure
   - Driver creation failed with empty values

### What Was Fixed

1. **Lazy Driver Initialization**
   - Moved driver creation inside async tool functions
   - Driver created after event loop starts
   - Single driver instance reused across requests
   - Clear error messages if credentials missing

2. **Environment Variable Reading**
   - Read credentials directly from `os.getenv()` inside `get_driver()`
   - Values survive FastMCP context
   - Works with Databricks Apps resource injection

3. **valueFrom Secret Management**
   - Configured resources in Databricks UI
   - Used `valueFrom` in app.yaml
   - Secrets properly injected at runtime
   - Follows official Microsoft documentation

### The Key Insight

**The core problem was timing**: Creating async resources before the async runtime (event loop) was ready.

**The solution was deferral**: Wait until the async context is established (when a tool is called) before creating async resources.

This pattern applies to any async resource in MCP servers on Databricks Apps:
- Database connections
- HTTP clients
- WebSocket connections
- Async file I/O

---

## Quick Reference

### Deployment Checklist

- [ ] Neo4j credentials in `neo4j_auth.txt`
- [ ] Resources configured in Databricks UI
- [ ] `app.yaml` uses `valueFrom` for secrets
- [ ] `app.yaml` hardcodes NEO4J_URI and NEO4J_DATABASE
- [ ] `server.py` uses lazy initialization pattern
- [ ] `production_server.py` doesn't create driver
- [ ] Databricks CLI authenticated: `databricks auth login`
- [ ] Deploy: `./deploy.sh`
- [ ] Test: `uv run test_neo4j_tools.py`

### Common Commands

```bash
# Deploy
./deploy.sh

# Check status
databricks apps get mcp-neo4j-cypher

# View logs
databricks apps logs mcp-neo4j-cypher

# Test
uv run test_neo4j_tools.py

# Get app URL
databricks apps get mcp-neo4j-cypher | jq -r '.url'
```

### Key Files

- `src/mcp_neo4j_cypher/server.py` - Core server with lazy initialization
- `production_server.py` - Production wrapper
- `app.yaml` - Databricks app configuration
- `deploy.sh` - Deployment automation
- `test_neo4j_tools.py` - Testing script
- `neo4j_auth.txt` - Local credentials (gitignored)

---

## Conclusion

Deploying MCP servers to Databricks Apps requires understanding:

1. **Event loop lifecycle** and when async resources can be created
2. **Secret management differences** between notebooks and Apps
3. **Lazy initialization patterns** for async resources
4. **valueFrom approach** for secret injection

With these patterns in place, the MCP Neo4j server runs reliably in production on Databricks Apps.

**Deployment Time**: ~10 minutes
**Success Rate**: 100% (with proper configuration)
**Status**: Production Ready ‚úÖ

---

**For Questions or Issues**: See the Troubleshooting section or check `databricks apps logs mcp-neo4j-cypher`
